=pod

=encoding utf8

=head1 NAME

Goodscrapes - Goodreads.com HTML-API


=head1 VERSION

=over

=item * Updated: 2019-11-12

=item * Since: 2014-11-05

=back

=head1 COMPARED TO THE OFFICIAL API

=over

=item * focuses on analysing, not updating info on GR

=item * less limited, e.g., reading shelves and reviews of other members:
        Goodscrapes can scrape thousands of fulltext reviews.

=item * official is slow too; API users are even second-class citizen

=item * theoretically this library is more likely to break, 
        but Goodreads progresses very very slowly: nothing
        actually broke between 2019-2014 (I started this);
        actually their API seems to change more often than
        their web pages; they can and do disable API functions 
        without being noticed by the majority, but they cannot
        easily disable important webpages that we use too;
        There are unit-tests to detect markup changes on the
        scraped Goodreads.com website.

=item * this library grew with every new usecase and program;
        it retries operations on errors on Goodreads.com,
        which are not seldom (over capacity, exceptions etc);
        it saw a lot of flawed data such as wrong review dates 
        ("Jan 01, 1010"), which broke Time::Piece.

=item * Goodreads "isn't eating its own dog food"
        https://www.goodreads.com/topic/show/18536888-is-the-public-api-maintained-at-all#comment_number_1

=back


=head1 LIMITATIONS

=over

=item * slow: version with concurrent AnyEvent::HTTP requests was marginally 
        faster, so I sticked with simpler code; doesn't actually matter
        due to Amazon's and Goodreads' request throttling. You can only
        speed things up significantly with a pool of work-sharing computers 
        and unique IP addresses...

=item * just text pattern matching, no ECMAScript execution and DOM parsing
        (so far sufficient and faster)

=back


=head1 HOW TO USE

=over

=item * for real-world usage examples see Andre's Goodreads Toolbox

=item * C<_> prefix means I<private> function or constant (use in module only)

=item * C<ra> prefix means array reference, C<rh> prefix means hash reference

=item * C<on> prefix or C<fn> suffix means function variable

=item * constants are uppercase, functions lowercase
	   
=item * Goodscrapes code in your program is usually recognizable by the
        'g' or 'GOOD' prefix in the function or constant name

=item * common internal abbreviations: 
        pfn = progress function, bfn = book handler function, 
        pag = page number, nam = name, au = author, bk = book, uid = user id,
        bid = book id, aid = author id, rat = rating, tit = title, 
        q   = query string, slf = shelf name, shv = shelves names, 
        t0  = start time of an operation, ret = return code, 
        tmp = temporary helper variable, gp = group, gid = group id,
	   us  = user

=back


=head1 AUTHOR

https://github.com/andre-st/


=head1 DATA STRUCTURES

=head2 Note

=over

=item * never cast 'id' to int or use %d format string, despite digits only, 
        compare as strings

=item * don't expect all attributes set (C<undef>), 
        this depends on the available info on the scraped page

=back



=head2 %book

=over

=item * id              =E<gt> C<string>

=item * title           =E<gt> C<string>

=item * isbn            =E<gt> C<string>

=item * isbn13          =E<gt> C<string>

=item * num_pages       =E<gt> C<int>

=item * num_reviews     =E<gt> C<int>

=item * num_ratings     =E<gt> C<int>    103 for example

=item * avg_rating      =E<gt> C<float>  4.36 for example

=item * stars           =E<gt> C<int>    rounded avg_rating, e.g., 4

=item * format          =E<gt> C<string> (binding)

=item * user_rating     =E<gt> C<int>    number of stars 1,2,3,4 or 5

=item * user_read_count =E<gt> C<int>

=item * user_num_owned  =E<gt> C<int>

=item * user_date_read  =E<gt> C<Time::Piece>

=item * user_date_added =E<gt> C<Time::Piece>

=item * ra_user_shelves =E<gt> C<string[]> reference

=item * url             =E<gt> C<string>

=item * img_url         =E<gt> C<string>

=item * review_id       =E<gt> C<string>

=item * year            =E<gt> C<int>     (original publishing date)

=item * year_edit       =E<gt> C<int>     (edition publishing date)

=item * rh_author       =E<gt> C<L<%user|"%user">> reference

=back



=head2 %user

=over

=item * id          =E<gt> C<string>

=item * name        =E<gt> C<string>  "Firstname Lastname"

=item * name_lf     =E<gt> C<string>  "Lastname, Firstname"

=item * residence   =E<gt> C<string>  (might require login)

=item * age         =E<gt> C<int>     (might require login)

=item * num_books   =E<gt> C<int>

=item * is_friend   =E<gt> C<bool>

=item * is_author   =E<gt> C<bool>

=item * is_female   =E<gt> C<bool>

=item * is_private  =E<gt> C<bool>

=item * is_staff    =E<gt> C<bool>, is a Goodreads.com employee

=item * url         =E<gt> C<string> URL to the user's profile page

=item * works_url   =E<gt> C<string> URL to the author's distinct works (is_author == 1)

=item * img_url     =E<gt> C<string>

=item * _seen       =E<gt> C<int>    incremented if user already exists in a load-target structure

=back



=head2 %review

=over

=item * id          =E<gt> C<string>

=item * rh_user     =E<gt> C<L<%user|"%user">> reference

=item * book_id     =E<gt> C<string>

=item * rating      =E<gt> C<int> 
                       with 0 meaning no rating, "added" or "marked it as abandoned" 
                       or something similar

=item * rating_str  =E<gt> C<string> 
                       represention of rating, e.g., 3/5 as S<"[***  ]"> or S<"[TTT  ]"> 
                       if there's additional text, or S<"[ttt  ]"> if not longer than 160 chars

=item * text        =E<gt> C<string>

=item * date        =E<gt> C<Time::Piece>

=item * url         =E<gt> C<string>  full text review

=back



=head2 %group

=over

=item * id          =E<gt> C<string>

=item * name        =E<gt> C<string>

=item * url         =E<gt> C<string>

=item * img_url     =E<gt> C<string>

=item * num_members =E<gt> int

=back


=head1 PUBLIC ROUTINES



=head2 C<string> gverifyuser( I<$user_id_to_verify> )

=over

=item * returns a sanitized, valid Goodreads user id or kills 
        the current process with an error message

=back

=head2 C<string> gverifyshelf( I<$name_to_verify> )

=over

=item * returns the given shelf name if valid 

=item * returns a shelf which includes all books if no name given

=item * kills the current process with an error message if name is malformed

=back

=head2 C<bool> gisbaduser( I<$user_or_author_id> )

=over

=item * returns true if the given user or author is blacklisted 
        and would slow down any analysis

=back

=head2 C<sub> gmeter( I<$unit_str = ''> )

=over

=item * generates and returns a CLI progress indicator function $f, 
        with I<$f-E<gt>( 20 )> adding 20 to the last values and 
        printing the sum like "40 unit_str".
        Given a second (max value) argument I<$f-E<gt>( 10, 100 )>, 
        it will print a percentage without any unit: "10%".
        Given a modern terminal, the text remains at the same 
        position if the progress function is called multiple times.

=back

=head2 C<void> glogin(I<{ ... }>)

=over

=item * some Goodreads.com pages are only accessible by authenticated members

=item * C<usermail =E<gt> string>

=item * C<userpass =E<gt> string> 

=item * C<r_userid =E<gt> string ref> set user ID if variable is empty/undef [optional]

=back

=head2 C<void> gsetopt(I<{ ... }>)

=over

=item * change one or multiple library-scope parameters

=item * C<ignore_errors =E<gt> bool>
        disables retries for [ERROR] and [CRIT] with the process just keep going with the next step

=item * C<maxretries =E<gt> int> 
        sets number of retries when there is an error, 
        critical issues are retried indefinitely (if ignore_errors is false)

=item * C<retrydelay_secs =E<gt> int>

=item * C<cache_days =E<gt> int>
        sets the number of days that a resource can be loaded from the local storage.
        Scraping Goodreads.com is a very slow process;
        scraped documents can be cached if you don't need them "fresh"
        during development time
        or long running sessions (cheap recovery on crash, power blackout or pauses),
        or when experimenting with parameters

=back

=head2 C<L<%book|"%book">> greadbook( $book_id )

=head2 C<L<%user|"%user">> greaduser( $user_id, $prefer_author = 0 )

=over

=item * there can be a different user and author with the same ID 
        (2456: Joana vs Chuck Palahniuk); 
        if there's no user but an author, Goodreads would redirect 
        to the author page with the same ID and this function
        would return the author

=item * if ambiguous you can set the I<$prefer_author> flag

=back

=head2 C<void> greadusergp(I<{ ... }>)

=over

=item * reads all group memberships of the given user into I<rh_into>

=item * C<from_user_id =E<gt> string>

=item * C<rh_into      =E<gt> hash reference (id =E<gt> L<%group|"%group">,...)>

=item * C<on_group     =E<gt> sub( L<%group|"%group"> )> [optional]

=item * C<on_progress  =E<gt> sub> see C<gmeter()> [optional]

=back

=head2 C<void> greadshelf(I<{ ... }>)

=over

=item * reads a list of books present in the given shelves of the given user

=item * C<from_user_id    =E<gt> string>

=item * C<ra_from_shelves =E<gt> string-array reference> with shelf names

=item * C<rh_into         =E<gt> hash reference (id =E<gt> L<%book|"%book">,...)> [optional]

=item * C<on_book         =E<gt> sub( L<%book|"%book"> )> [optional]

=item * C<on_progress     =E<gt> sub> see C<gmeter()> [optional]

=back

=head2 C<void> greadauthors(I<{ ... }>)

=over

=item * gets a list of authors whose books are present in the given shelves of the given user

=item * C<from_user_id    =E<gt> string>

=item * C<ra_from_shelves =E<gt> string-array reference> with shelf names

=item * C<rh_into         =E<gt> hash reference (id =E<gt> L<%user|"%user">,...)> [optional]

=item * C<on_progress     =E<gt> sub> see C<gmeter()> [optional]

=item * If you need authors I<and> books data, then use C<greadshelf>
        which also populates the I<author> property of every book

=item * skips authors where C<gisbaduser()> is true

=back

=head2 C<void> greadauthorbk(I<{ ... }>)

=over

=item * reads the Goodreads.com list of books written by the given author

=item * C<author_id   =E<gt> string>

=item * C<limit       =E<gt> int> number of books to read into C<rh_into>

=item * C<rh_into     =E<gt> hash reference (id =E<gt> L<%book|"%book">,...)>

=item * C<on_book     =E<gt> sub( L<%book|"%book"> )> [optional]

=item * C<on_progress =E<gt> sub> see C<gmeter()> [optional]

=back

=head2 C<void> greadreviews(I<{ ... }>)

=over

=item * loads ratings (no text), reviews (text), "to-read", "added" etc;
        you can filter later or via I<on_filter> parameter

=item * C<rh_for_book =E<gt> hash reference L<%book|"%book">>, see C<greadbook()>

=item * C<rh_into     =E<gt> hash reference (id =E<gt> L<%review|"%review">,...)>

=item * C<since       =E<gt> Time::Piece> [optional]

=item * C<on_filter   =E<gt> sub( L<%review|"%review"> )>, return 0 to drop [optional]

=item * C<on_progress =E<gt> sub> see C<gmeter()> [optional]

=item * C<dict_path   =E<gt> string> path to a dictionary file (1 word per line) [optional]

=item * C<text_only   =E<gt> bool> overwrites C<on_filter> argument [optional, default 0 ]

=item * C<rigor       =E<gt> int> [optional, default 2]

  level 0   = search newest reviews only (max 300 ratings)
  level 1   = search with a combination of filters (max 5400 ratings)
  level 2   = like 1 plus dict-search if more than 3000 ratings with stall-time of 2 minutes
  level n   = like 1 plus dict-search with stall-time of n minutes

=back

=head2 C<void> greadfolls(I<{ ... }>)

=over

=item * queries Goodreads.com for the friends and followees list of the given user

=item * C<rh_into            =E<gt> hash reference (id =E<gt> L<%user|"%user">,...)>

=item * C<from_user_id       =E<gt> string>

=item * C<on_user            =E<gt> sub( %user )> return false to exclude user from $rh_into [optional]

=item * C<on_progress        =E<gt> sub> see C<gmeter()> [optional]

=item * C<discard_threshold> =E<gt> number> don't add anything to $rh_into if number of folls exceeds limit [optional];
                                    use this to drop degenerated accounts which would just add noise to the data

=item * C<incl_authors       =E<gt> bool> [optional, default 1]

=item * C<incl_friends       =E<gt> bool> [optional, default 1]

=item * C<incl_followees     =E<gt> bool> [optional, default 1]

=item * Precondition: glogin()

=back

=head2 C<void> gsocialnet(I<{ ... }>)

=over

=item * C<from_user_id    =E<gt> string>

=item * C<rh_into_nodes   =E<gt> hash reference (id =E<gt> L<%user|"%user">,...)>

=item * C<ra_into_edges   =E<gt> array reference ({from =E<gt> id, to =E<gt> id},...)>

=item * C<ignore_nhood_gt =E<gt> int> ignore users with with a neighbourhood > N [optional, default 1000];
                                      such users just add noise to the data and waste computing time

=item * C<depth           =E<gt> int>  [optional, default 1]

=item * C<incl_authors    =E<gt> bool> [optional, default 0]

=item * C<incl_friends    =E<gt> bool> [optional, default 1]

=item * C<incl_followees  =E<gt> bool> [optional, default 1]

=item * C<on_progress     =E<gt> sub({ done =E<gt> int, count =E<gt> int, perc =E<gt> int, depth =E<gt> int })>  [optional]

=item * C<on_user         =E<gt> sub( %user )> return false to exclude user [optional]

=item * Precondition: glogin()

=back

=head2 C<void> greadsimilaraut(I<{ ... }>)

=over

=item * reads the Goodreads.com list of authors who are similar to the given author

=item * C<rh_into     =E<gt> hash reference (id =E<gt> L<%user|"%user">,...)>

=item * C<author_id   =E<gt> string>

=item * C<on_progress =E<gt> sub> see C<gmeter()> [optional]

=item * increments C<'_seen'> counter of each author if already in I<%$rh_into>

=back

=head2 C<void> gsearch(I<{ ... }>)

=over

=item * searches the Goodreads.com database for books that match a given phrase

=item * C<ra_into     =E<gt> array reference (L<%book|"%book">,...)> 

=item * C<phrase      =E<gt> string> with space separated keywords

=item * C<is_exact    =E<gt> bool> [optional, default 0]

=item * C<ra_order_by =E<gt> array reference> property names from C<L<%book|"%book">> 
                       [optional, default: 'stars', 'num_ratings', 'year']

=item * C<num_ratings =E<gt> int> only list books with at least N ratings [optional, default 0]

=item * C<on_progress =E<gt> sub> see C<gmeter()>  [optional]

=back

=head2 C<string> amz_book_html( I<L<%book|"%book">> )

=over

=item * HTML body of an Amazon article page

=back

=head1 PUBLIC REPORT-GENERATION HELPERS



=head2 C<string> ghtmlhead( I<$title, $ra_cols > )

=over

=item * returns a string with HTML boiler plate code for a table-based report

=item * $title: HTML title, Table caption

=item * $ra_cols: [ "Normal", ">Sort ASC", "<Sort DESC", "!Not sortable/searchable", "Right-Aligned:", ">Sort ASC, right-aligned:", ":Centered:" ]

=back

=head2 C<string> ghtmlfoot()

=over

=item * returns a string with HTML boiler plate code for a table-based report

=back

=head2 C<string> ghtmlsafe(I<$string>)

=over

=item * always use this when generating HTML reports in order to prevent 
        cross site scripting attacks (XSS) through malicious text on the 
        Goodreads.com website

=back

=head2 C<void> ghistogram(I<{ ... }>)

=over

=item * prints a year-based histogram for the given hash on the terminal

=item * C<rh_from    =E<gt> hash reference (id =E<gt> %any,...)>

=item * C<date_key   =E<gt> string> name of the Time::Piece component of any hash item [optional, default 'date']

=item * C<start_year =E<gt> int> [optional, default 2007]

=item * C<title      =E<gt> string> [optional, default '...reviews...']

=item * C<bar_width  =E<gt> int> [optional, default 40]

=item * C<bar_char   =E<gt> char> [optional, default '#']

=back

=head1 PRIVATE URL-GENERATION ROUTINES



=head2 C<string> _amz_url( I<L<%book|"%book">> )

=over

=item * Requires at least {isbn=E<gt>string}

=back

=head2 C<string> _shelf_url( I<$user_id, $shelf_name, $page_number = 1> )

=over

=item * URL for a page with a list of books (not all books)

=item * "&print=true" allows 200 items per page with a single request, 
        which is a huge speed improvement over loading books from the "normal" 
        view with max 20 books per request.
        Showing 100 books in normal view is oddly realized by 5 AJAX requests
        on the Goodreads.com website.

=item * "&per_page" in print-view can be any number if you work with your 
        own shelf, otherwise max 200 if print view; ignored in non-print view;
        per_page>20 requires access with a cookie, see glogin()

=item * "&view=table" puts I<all> book data in code, although invisible (display=none)

=item * "&sort=rating" is important for `friendrated.pl` with its book limit:
        Some users read 9000+ books and scraping would take forever. 
        We sort lower-rated books to the end and I<could> just scrape the first pages:
        Even those with 9000+ books haven't top-rated more than 2700 books.

=item * "&shelf" supports intersection "shelf1%2Cshelf2" (comma)

=item * B<Warning:> changes to the URL structure will bust the file-cache

=back

=head2 C<string> _followees_url( I<$user_id, $page_number = 1> )

=over

=item * URL for a page with a list of the people $user is following

=item * B<Warning:> changes to the URL structure will bust the file-cache

=back

=head2 C<string> _friends_url( I<$user_id, $page_number = 1> )

=over

=item * URL for a page with a list of people befriended to C<$user_id>

=item * "&sort=date_added" (as opposed to 'last online') avoids 
        moving targets while reading page by page

=item * "&skip_mutual_friends=false" because we're not doing
        this just for me

=item * B<Warning:> changes to the URL structure will bust the file-cache

=back

=head2 C<string> _book_url( I<$book_id> )

=head2 C<string> _user_url( I<$user_id, $is_author = 0> )

=head2 C<string> _revs_url( I<$book_id, $str_sort_newest_oldest = undef, 
		$search_text = undef, $rating = undef, $is_text_only = undef, $page_number = 1> )

=over

=item * "&sort=newest" and "&sort=oldest" reduce the number of reviews for 
        some reason (also observable on the Goodreads website), 
        so only use if really needed (&sort=default)

=item * "&search_text=example" invalidates sort order argument

=item * "&rating=5"

=item * "&text_only=true" just returns 1 page, you might get more text-reviews without this flag

=item * the maximum of retrievable pages is 10 (300 reviews), see
        https://www.goodreads.com/topic/show/18937232-why-can-t-we-see-past-page-10-of-book-s-reviews?comment=172163745#comment_172163745

=item * seems less throttled, not true for text-search

=back

=head2 C<string> _rev_url( I<$review_id> )

=head2 C<string> _author_books_url( I<$user_id, $page_number = 1> )

=head2 C<string> _author_followings_url( I<$author_id, $page_number = 1> )

=head2 C<string> _similar_authors_url( I<$author_id> )

=over

=item * page number > N just returns same page, so no easy stop criteria;
        not sure, if there's more than page, though

=back

=head2 C<string> _search_url( I<phrase_str, $page_number = 1> )

=over

=item * "&q=" URL-encoded, e.g., linux+%40+"hase (linux @ "hase)

=back

=head2 C<string> _user_groups_url( I<$user_id>, I<$page_number = 1> )

=head2 C<string> _group_url( I<$group_id> )

=head1 PRIVATE HTML-EXTRACTION ROUTINES



=head2 C<L<%book|"%book">> _extract_book( $book_page_html_str )

=head2 C<L<%user|"%user">> _extract_user( $user_page_html_str )

=head2 C<L<%user|"%user">> _extract_author( $user_page_html_str )

=head2 C<bool> _extract_books( I<$rh_books, $on_book_fn, $on_progress_fn, $shelf_tableview_html_str> )

=over

=item * I<$rh_books>: C<(id =E<gt> L<%book|"\%book">,...)>

=item * returns 0 if no books, 1 if books, 2 if error

=back

=head2 C<bool> _extract_author_books( I<$rh_books, $r_limit, $on_book_fn, $on_progress_fn, $html_str> )

=over

=item * I<$rh_books>: C<(id =E<gt> L<%book|"\%book">,...)>

=item * I<$r_limit>: is counted to zero

=item * returns 0 if no books, 1 if books, 2 if error

=back

=head2 C<bool> _extract_followees( I<$rh_users, $on_progress_fn, $incl_authors, $discard_threshold, $following_page_html_str> )

=over

=item * I<$rh_users>: C<(user_id =E<gt> L<%user|"\%user">,...)>

=item * returns 0 if no followees, 1 if followees, 2 if error

=back

=head2 C<bool> _extract_friends( I<$rh_users, $on_progress_fn, $incl_authors, $discard_threshold, $friends_page_html_str> )

=over

=item * I<$rh_users>: C<(user_id =E<gt> L<%user|"\%user">,...)> 

=item * returns 0 if no friends, 1 if friends, 2 if error

=back

=head2 C<string> _conv_uni_codepoints( I<$string> )

=over

=item Convert Unicode codepoints such as \u003c

=back

=head2 C<string> _dec_entities( I<$string> )

=head2 C<$value> _require_arg( I<$name, $value> )

=head2 C<string> _trim( I<$string> )

=head2 C<bool> _extract_revs( I<$rh_revs, $on_progress_fn, $filter_fn, $since_time_piece, $reviews_xhr_html_str> )

=over

=item * I<$rh_revs>: C<(review_id =E<gt> L<%review|"\%review">,...)>

=item * returns 0 if no reviews, 1 if reviews, 2 if error

=back

=head2 C<bool> _extract_similar_authors( I<$rh_into, $author_id_to_skip, 
			$on_progress_fn, $similar_page_html_str> )

=over

=item * returns 0 if no authors, 1 if authors, 2 if error

=back

=head2 C<bool> _extract_search_books( I<$ra_books, $on_progress_fn, $search_result_html_str>  )

=over

=item * result pages sometimes have different number of items: 
        P1: 20, P2: 16, P3: 19

=item * website says "about 75 results" but shows 70 (I checked that manually).
        So we fake "100%" to the progress indicator function at the end,
        otherwise it stops with "93%".

=item * I<ra_books>: C<(L<%book|"\%book">,...)> 

=item * returns 0 if no books, 1 if books, 2 if error

=back

=head2 C<bool> _extract_user_groups( I<$rh_into, $on_group_fn, on_progress_fn, $groups_html_str> )

=over

=item * returns 0 if no groups, 1 if groups, 2 if error

=back

=head2 C<string> _extract_csrftok(I< $html >)

=over

=item Example:
	my $csrftok = _extract_csrftok( _html( _user_url( $uid ) ) );
	$curl->setopt( $curl->CURLOPT_HTTPHEADER, [ "X-CSRF-Token: ${csrftok}",

=back

=head1 PRIVATE I/O PLUMBING SUBROUTINES




=head2 C<int> _check_page( I<$any_html_str> )

=over

=item * returns I<$_ENO_XXX> constants

=item * warn if sign-in page (https://www.goodreads.com/user/sign_in) or in-page message

=item * warn if "page unavailable, Goodreads request took too long"

=item * warn if "page not found" 

=item * error if page unavailable: "An unexpected error occurred. 
	We will investigate this problem as soon as possible"

=item * error if over capacity (TODO UNTESTED):
        "<?>Goodreads is over capacity.</?> 
        <?>You can never have too many books, but Goodreads can sometimes
        have too many visitors. Don't worry! We are working to increase 
        our capacity.</?>
        <?>Please reload the page to try again.</?>
        <a ...>get the latest on Twitter</a>"
        https://pbs.twimg.com/media/DejvR6dUwAActHc.jpg
        https://pbs.twimg.com/media/CwMBEJAUIAA2bln.jpg
        https://pbs.twimg.com/media/CFOw6YGWgAA1H9G.png  (with title)

=item * error if maintenance mode (TODO UNTESTED):
        "<?>Goodreads is down for maintenance.</?>
        <?>We expect to be back within minutes. Please try again soon!<?>
        <a ...>Get the latest on Twitter</a>"
        https://pbs.twimg.com/media/DgKMR6qXUAAIBMm.jpg
        https://i.redditmedia.com/-Fv-2QQx2DeXRzFBRKmTof7pwP0ZddmEzpRnQU1p9YI.png

=item * error if website temporarily unavailable (TODO UNTESTED):
        "Our website is currently unavailable while we make some improvements
        to our service. We'll be open for business again soon,
        please come back shortly to try again. <?>
        Thank you for your patience." (No Alice error)
        https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/hostedimages/1404319071i/10224522.png

=back

=head2 C<void> _updcookie(I< $string_with_changed_fields >)

=over

=item updates "_session_id2" for X-CSRF-Token, "csid", "u" (user?). "p" (password?)

=back

=head2 C<void> _setcurlopts(I< $curl_ref >, I< $url_str >)

=over

=item Sets default options for GET, POST, PUT, DELETE

=back

=head2 C<string> _html( I<$url, $warn_level = $_ENO_WARN, $can_cache = 1> )

=over

=item * HTML body of a web document

=item * caches documents (if I<$can_cache> is true)

=item * retries on errors

=back

